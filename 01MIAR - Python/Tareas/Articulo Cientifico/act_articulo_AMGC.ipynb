{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "\n",
    "# Análisis crítico artículos cientificos sobre Numpy y Pandas\n",
    "#### *Angele Mauricio Guevara Chinchero*\n",
    "\n",
    "</div>\n",
    "\n",
    "### Objetivos:\n",
    "- Leer y analizar críticamente dos artículos científicos.\n",
    "\n",
    "### Instrucciones:\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "- Crear un notebook de Python que servirá como entrega de la actividad.\n",
    "- Separar bien los apartados propuestos con celdas Markdown.\n",
    "- Mantener una estructura limpia, comentando código y secuenciando los\n",
    "apartados con el código correspondiente que resuelva la actividad.\n",
    "- Como criterio de evaluación se tendrá en cuenta el resultado, la consecución del\n",
    "mismo, estilo, comentarios y adecuación. Siempre será tenido en cuenta cualquier\n",
    "detalle técnico avanzado o no visto en clase relacionado con el tema (explicar el\n",
    "porqué y usabilidad).\n",
    "- No está permitido compartir los resultados ni el código en ninguno de los foros.\n",
    "- Revisar los temas 3 y 4, así como las sesiones sobre Numpy y Pandas para\n",
    "aplicar dichos contenidos.\n",
    "\n",
    "</div>\n",
    "\n",
    "### Tarea para el portfolio:\n",
    "##### En el artículo 1 se presenta la estructura ndarray de NumPy, y se hace un estudio sobre su uso y cómo mejora el rendimiento de ciertas operaciones matemáticas para la computación numérica. Se hace una breve introducción al Broadcasting como técnica que usa NumPy para realizar operaciones aritméticas sobre dos o más arrays con distintas dimensiones:\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "- Pregunta 1 - Ampliar dicha explicación, aportando posibles restricciones o limitaciones a dicho sistema y ejemplos propios de los casos de uso. También se introduce el trabajo con ficheros usando memoria mapeada:\n",
    "- Pregunta 2 - Verificar la eficacia y mejora posible de rendimiento del uso de \n",
    "memoria mapeada sobre ndarrays de tamaños grandes.\n",
    "\n",
    "</div>\n",
    "\n",
    "##### En el artículo 2 el creador de pandas introduce dicha librería en comparación con las estructuras nativas de R.\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "- Pregunta 3 - Desarrollar una opinión razonada del estado actual de las\n",
    "herramientas de análisis de datos estadísticos en contraposición a como se muestran\n",
    "en el artículo, R vs Python vs SQL vs Others...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El array de NumPy: Una estructura para computación numérica eficiente.\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "Los arrays NumPy en Python son empleados para realizar cálculos numéricos eficientes. Los arrays NumPy son la representación estándar para datos numéricos en Python y se utilizan para mejorar el rendimiento mediante la vectorización de cálculos, evitando copiar datos en memoria y minimizando la cantidad de operaciones.\n",
    "\n",
    "Para llegar a este resultado partimos de que los arrays NumPy es una colección uniforme multidimensional de elementos de los cuales se puede formar vectores o matrices de M filas x N columnas (MxN). Estas colecciones pueden contener numeros como enteros, flotantes o complejos, asi como otros tipos de elementos como booleans o dates.\n",
    "\n",
    "Su estructura es la siguiente:\n",
    "- Puntero de datos: la dirección de memoria del primer byte en el arreglo.\n",
    "- Descripción del tipo de datos: el tipo de elementos contenidos en el arreglo, por ejemplo, float o int.\n",
    "- Forma: la forma del arreglo, por ejemplo, (10, 10) para un arreglo de diez por diez, o (5, 5, 5) para un bloque de datos que describe una cuadrícula de coordenadas x, y y z.\n",
    "- Pasos: el número de bytes a saltar en la memoria para avanzar al siguiente elemento. Por ejemplo, para un arreglo (10, 10) de bytes, los pasos pueden ser (10, 1), es decir, avanzar un byte para obtener la siguiente columna y diez bytes para localizar la siguiente fila.\n",
    "- Banderas: definen si se permite modificar el arreglo, si el diseño de memoria es contiguo en estilo C o en estilo Fortran, y otros aspectos.\n",
    "\n",
    "El artículo presenta la estructura de los arrays NumPy, cómo utilizarlos para cálculos eficientes y cómo compartir datos de arrays con otras bibliotecas. Describe que un array NumPy es una colección multidimensional y uniforme de elementos con un tipo de dato y forma específicos. Los arrays NumPy pueden tener cualquier dimensionalidad y pueden contener diferentes tipos de elementos.\n",
    "\n",
    "Se explica la estructura de un array NumPy, incluyendo el puntero de datos, la descripción del tipo de datos, la forma, los pasos y las banderas. Se destaca el modelo de memoria estratificado de NumPy, que permite ver la misma memoria de diferentes formas sin copiar datos. Se muestran ejemplos de cómo crear vistas en la memoria y cómo transponer o remodelar arrays sin copiar datos.\n",
    "\n",
    "El texto también resalta la importancia de la vectorización en NumPy para mejorar el rendimiento en operaciones numéricas. Se explica que las operaciones vectorizadas en NumPy se implementan en C, lo que resulta en una mejora significativa de la velocidad. Se menciona la transmisión de operaciones entre arrays de formas compatibles y cómo NumPy expande los arrays para que las operaciones sean posibles.\n",
    "\n",
    "Además, se presentan ejemplos de cómo evaluar funciones en arrays, realizar diferencias finitas y crear rejillas utilizando la transmisión. Se destaca la capacidad de NumPy para realizar operaciones \"en el lugar\" y evitar la creación de grandes arrays temporales como los que se muestran a continuación\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias!!!\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(9).reshape((3, 3)) # inicialización de un narray con valores del 0 al 9 dispuesto en 3 filas y 3 columnas\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [6, 8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x[::2, ::2] # asignación de la matriz x del 0 al final saltando 2 filas y 2 columnas \n",
    "                # utilizan el mismo puntero por lo que no necesitan crear una copia de los datos\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100,   1,   2],\n",
       "       [  3,   4,   5],\n",
       "       [  6,   7,   8]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, 0] = 100 # al utilizar el mismo puntero, cualquier cambio que se haga en la matriz y tambien se hace en la matriz x\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estos son otros ejemplos que permiten que las operaciones no tengan costo en memoria porque hacen referencia al puntero original\n",
    "xT = x.T # Transpuesta: cambia filas por columnas\n",
    "z = x.reshape((1, 9)) # Redimensionar: Cambiar el tamaño de la matriz\n",
    "z.dtype = np.dtype('uint8') # Cambiar el tipo de entero"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones en NumPy son realizados en C lo que resulta un gran desempeño en el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 403 ms, sys: 124 ms, total: 527 ms\n",
      "Wall time: 527 ms\n"
     ]
    }
   ],
   "source": [
    "# Tiempo de respuesta de ejecución de un escalar por un array\n",
    "a = list(range(10000000))\n",
    "b = [3*x for x in a]\n",
    "%time b = [3*x for x in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 ms, sys: 8.45 ms, total: 21.4 ms\n",
      "Wall time: 21.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Tiempo de respuesta de ejecución de un escalar por un narray\n",
    "a = np.arange(10000000)\n",
    "b = 3 * a\n",
    "%time b = 3 * a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "Como se puede observar, realizar una operación en una lista normal de 1 millon de registros utilizando un loop tarda 527 ms mientras que utilizando NumPy el tiempo de ejecución es de 21.4 ms es decir, utilizar ndarray es 25 veces mas rapido que utilizar listas para hacer una operación matemática.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "Aparece el concepto de Broadcasting, que es un método que utiliza NumPy para permitir operaciones entre matrices de diferentes dimensiones. Esto se logra expandiendo el array más pequeño.\n",
    "\n",
    "Cuando se realiza una operación matemática de matrices de diferentes dimensiones se produce una transmisión, que es el estiramiento de la matriz más pequeña para que coincida con la más grande y la operación se pueda efectuar.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"img/broadcasting_2.png\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -2, -3],\n",
       "       [ 2,  1,  0],\n",
       "       [ 5,  4,  3],\n",
       "       [ 8,  7,  6]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.arange(12).reshape((4,3))\n",
    "n = np.array([1, 3, 5]) \n",
    "m - n # duplica la fila del ndarray n para que tome la forma del ndarray m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cuando las dimensiones finales de los arreglos son desiguales, la transmisión falla porque es imposible alinear los valores en las filas del primer arreglo con los elementos del segundo arreglo para la suma de elemento por elemento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"img/broadcasting_3.png\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/guevara/Documentos/Master_git/01MIAR - Python/Tareas/Angel Guevara - 01MAIR_Análisis Crítico Artículos.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/guevara/Documentos/Master_git/01MIAR%20-%20Python/Tareas/Angel%20Guevara%20-%2001MAIR_An%C3%A1lisis%20Cr%C3%ADtico%20Art%C3%ADculos.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m12\u001b[39m)\u001b[39m.\u001b[39mreshape((\u001b[39m4\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/guevara/Documentos/Master_git/01MIAR%20-%20Python/Tareas/Angel%20Guevara%20-%2001MAIR_An%C3%A1lisis%20Cr%C3%ADtico%20Art%C3%ADculos.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m n \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m]) \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/guevara/Documentos/Master_git/01MIAR%20-%20Python/Tareas/Angel%20Guevara%20-%2001MAIR_An%C3%A1lisis%20Cr%C3%ADtico%20Art%C3%ADculos.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m m \u001b[39m-\u001b[39;49m n\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (4,) "
     ]
    }
   ],
   "source": [
    "m = np.arange(12).reshape((4,3))\n",
    "n = np.array([1, 3, 5, 6]) \n",
    "\n",
    "m + n # duplica la fila del array n para que tome la forma del array m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos, la transmisión amplía ambos arreglos para formar un arreglo de salida más grande que cualquiera de los arreglos iniciales."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"img/broadcasting_4.png\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [11., 12., 13.],\n",
       "       [21., 22., 23.],\n",
       "       [31., 32., 33.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0.0, 10.0, 20.0, 30.0]])\n",
    "b = np.array([1.0, 2.0, 3.0])\n",
    "a.T + b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manejo de grandes cantidades de datos\n",
    "Usando un loop for para guardar un resultado como array vs enviar el ndarray directamente a la función\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.9 ms, sys: 8.11 ms, total: 58.1 ms\n",
      "Wall time: 57.1 ms\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**2 - 3*x + 4 \n",
    "x = np.arange(1e5) \n",
    "%time y = [f(i) for i in x] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 ms, sys: 4.15 ms, total: 6.94 ms\n",
      "Wall time: 17.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time y = f(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual forma, al utilizar las listas directamente como variables y no tener que utilizar iteraciones reduce notablemente el tiempo de ejecución"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "Otra de las bondades de broadcasting esta en su capacidad para realizar cálculos en un conjunto de datos tridimensional. En lugar de crear grandes matrices temporales para almacenar los resultados intermedios, se utilizan las capacidades de broadcasting de NumPy para combinar tres vectores unidimensionales y obtener el resultado tridimensional deseado. Esto se logra mediante el uso de las funciones np.reshape o np.ogrid para construir los vectores de coordenadas i, j y k.\n",
    "\n",
    "Una vez que se construyen los vectores de coordenadas, se realiza la operación de cálculo de distancia utilizando la fórmula de la distancia euclidiana. El uso del broadcasting permite realizar esta operación de manera eficiente y sin la necesidad de crear grandes matrices temporales. Además, se destaca que el uso de broadcasting reduce significativamente la cantidad de memoria utilizada en comparación con enfoques no vectorizados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"img/broadcasting.png\" width=\"700\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "R = np.zeros((200, 200, 200), dtype=int)\n",
    "\n",
    "for i in range(-100, 100):\n",
    "    for j in range(-100, 100):\n",
    "        for k in range(-100, 100):\n",
    "           R[i][j][k] = int(np.sqrt(i*i + j*j + k*k))\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construye la fila del vector: from -100 to +100\n",
    "i = np.arange(-100, 100).reshape(200, 1, 1)\n",
    "# Construye la columna del vector\n",
    "j = np.reshape(i, (1, 200, 1))\n",
    "# Construye la profundidad del vector\n",
    "k = np.reshape(i, (1, 1, 200))\n",
    "i, j, k = np.ogrid[-100:100, -100:100, -100:100]\n",
    "R = np.sqrt(i**2 + j**2 + k**2)\n",
    "R.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo de ejecución para construir una matriz de 3 dimensiones toma más tiempo que construirla mediante las funciones de NumPy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoria Mapeada\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "La memoria mapeada (memory mapping) es una técnica utilizada para acceder y manipular datos almacenados en un archivo en el disco, como si estuvieran en la memoria principal de un programa. En Python, NumPy ofrece soporte para arrays de memoria mapeada a través de la función np.memmap().\n",
    "\n",
    "La memoria mapeada es útil cuando se trabaja con archivos de gran tamaño y solo se necesita acceder o manipular una parte específica de ellos en un momento dado, en lugar de cargar todo el archivo en memoria. Esto ahorra memoria y permite un acceso más eficiente a los datos.\n",
    "\n",
    "En el ejemplo proporcionado, se muestra cómo utilizar la memoria mapeada en NumPy. Primero, se crea un archivo de memoria mapeada utilizando la función np.memmap(). El archivo se especifica con una ruta y un nombre de archivo, y se especifica el modo de acceso (por ejemplo, \"write\" para escritura o \"r+\" para lectura y escritura). También se especifica la forma y el tipo de datos del array que se almacenará en el archivo.\n",
    "\n",
    "Una vez creado el archivo de memoria mapeada, se pueden realizar operaciones en él como si fuera un array de NumPy convencional. En el ejemplo, se asigna una secuencia de valores a la variable a que representa el array de memoria mapeada. Los valores se asignan directamente a través del atributo flat del array.\n",
    "\n",
    "Cuando se llama al método flush() del array, los datos modificados se escriben nuevamente en el archivo en disco. Esto permite realizar cambios en los datos almacenados en el archivo sin tener que cargar y guardar todo el archivo cada vez.\n",
    "\n",
    "La memoria mapeada es especialmente útil cuando se trabaja con archivos binarios grandes y se necesita acceder a diferentes partes de ellos de forma eficiente. En lugar de leer y escribir manualmente los datos desde y hacia el archivo, NumPy se encarga de manejar la memoria y proporciona una interfaz conveniente para realizar operaciones en los datos almacenados en la memoria mapeada.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de uso de memmap con NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(12, dtype='float32')\n",
    "data.resize((3,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo usa un archivo temporal para que doctest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "filename = path.join(mkdtemp(), 'newfile.dat')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de un memmap con dtype y forma que coincida con nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = np.memmap(filename, dtype='float32', mode='w+', shape=(3,4))\n",
    "fp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escritura de datos en la matriz memmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp[:] = data[:]\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.filename == path.abspath(filename) #referencia al mismo archivo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vacía los cambios de memoria en el disco para volver a leerlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el memmap y verifique que los datos se almacenaron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newfp = np.memmap(filename, dtype='float32', mode='r', shape=(3,4))\n",
    "newfp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapa de memoria de solo lectura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr = np.memmap(filename, dtype='float32', mode='r', shape=(3,4))\n",
    "fpr.flags.writeable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memmap de copia en escritura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpc = np.memmap(filename, dtype='float32', mode='c', shape=(3,4))\n",
    "fpc.flags.writeable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible asignar una matriz de copia en escritura, pero los valores solo se escriben en la copia de memoria de la matriz y no se escriben en el disco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[ 0.,  0.,  0.,  0.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpc[0,:] = 0\n",
    "fpc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo en el disco no ha cambiado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compensación en un memmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([ 4.,  5.,  6.,  7.,  8.,  9., 10., 11.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpo = np.memmap(filename, dtype='float32', mode='r', offset=16)\n",
    "fpo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estructuras de datos para computación estadística en Python con pandas\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "Históricamente, los lenguajes dominantes en aplicaciones estadísticas en el ámbito científico han sido R, MATLAB, Stata y SAS. Sin embargo, Python ha logrado superar a todos estos lenguajes gracias a su biblioteca pandas, que actualmente es la preferida en el ámbito computacional y científico.\n",
    "\n",
    "Tanto R como pandas tienen una estructura de datos llamada data frame que puede almacenar diferentes tipos de datos y variar en tamaño. Sin embargo, pandas ofrece más funcionalidades a través de su clase DataFrame en comparación con R.\n",
    "\n",
    "Una funcionalidad destacada en pandas es el uso de pivote, que permite ajustar los índices de una tabla según el tipo de información que se desea consultar. Esto proporciona flexibilidad en la organización y análisis de los datos.\n",
    "\n",
    "La estructura interna de pandas vincula los ndarrays con índices únicos. Los índices pueden almacenar información de manera similar a un ndarray y también como un diccionario, lo que mejora el rendimiento al buscar relaciones.\n",
    "\n",
    "Los data frames de pandas permiten agregar nuevos índices a partir de otra lista y también se pueden crear máscaras para filtrar los índices y formar una nueva lista de índices. Los índices son importantes para realizar operaciones matemáticas de manera sencilla, como la suma entre dos data frames. En este caso, los datos se alinean automáticamente basándose en los índices para realizar la operación en cada valor. Es importante tener en cuenta que si no hay valores en la segunda tabla, la suma se reemplaza por NaN.\n",
    "\n",
    "NaN es una alternativa para detectar información faltante en los datos. NaN puede trabajar en operaciones de punto flotante y es fácil de detectar en el algoritmo. Sin embargo, no se puede utilizar en listas de tipo entero, donde se utiliza null para representar datos vacíos. Para tratar los NaN, se puede utilizar el método dropna() para eliminar los datos faltantes o el método fillna() para rellenar los valores faltantes con un valor específico. En los cálculos realizados con ndarrays, los métodos automáticamente excluyen los datos faltantes.\n",
    "\n",
    "La combinación y unión de conjuntos de datos es el proceso de asociar un data frame con otro utilizando una clave de combinación, lo que resulta en un data frame combinado donde los datos están relacionados según las claves de combinación. Esto es similar a un join entre dos tablas en SQL. Para realizar un join utilizando un campo que no sea el índice, se puede utilizar la sentencia data.join(cats, on='items').\n",
    "\n",
    "El group by y las variables de categoría se utilizan para realizar cálculos en conjuntos de datos. En pandas, se utiliza la función groupby y se agrega una operación utilizando el método aggregate. Por ejemplo, para calcular la media por etiquetas, se puede utilizar data.groupby(labels).aggregate(np.mean). También se pueden calcular las ocurrencias por índice utilizando data.groupby(ind).aggregate(len).\n",
    "\n",
    "El articulo llega a la conclusión de que Python es el mejor lenguaje de programación para aplicaciones estatisticas, sin embargo hay que analizar otros factores como los que se muestra a continuación.\n",
    "\n",
    "Pregunta 3 - Desarrollar una opinión razonada del estado actual de las herramientas de análisis de datos estadísticos en contraposición a como se muestran en el artículo, R vs Python vs SQL vs Others...\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "[1] Python es un lenguaje de programación orientado a objetos y es una buena herramienta para ejecutar algoritmos utilizados en producción. Por otro lado, R es un lenguaje de programación ampliamente utilizado por profesionales como estadísticos y analistas de datos. Se concluye que la elección del lenguaje depende del problema específico en cuestión. Esta es una comparación entre los dos lenguajes:\n",
    "- Flexibilidad: Python es más flexible y versátil, ya que se utiliza en una amplia gama de aplicaciones, como desarrollo web, análisis de datos y aprendizaje automático. Por otro lado, R se centra más en análisis estadístico y es ampliamente utilizado en ámbitos académicos y de investigación.\n",
    "\n",
    "- Facilidad de aprendizaje: Python es considerado más fácil de aprender y leer debido a su sintaxis sencilla y legible, que se asemeja al lenguaje inglés. R puede ser más complicado de aprender, especialmente para aquellos sin experiencia en programación, pero puede ser más intuitivo para estadísticos y analistas de datos.\n",
    "\n",
    "- Ecosistema: Python tiene un ecosistema fuerte y diverso, con una amplia variedad de bibliotecas y paquetes disponibles para diversas tareas de ciencia de datos. R también cuenta con una amplia gama de paquetes y librerías, pero tiende a estar más enfocado en análisis estadístico y visualización de datos.\n",
    "\n",
    "- Gráficos y visualizaciones: R se destaca en la generación de gráficos y visualizaciones atractivas y de alta calidad. La biblioteca ggplot2 es ampliamente utilizada para crear gráficos personalizados y sofisticados. Python también tiene bibliotecas de visualización poderosas, como Matplotlib y Seaborn, pero se considera que R ofrece más opciones y flexibilidad en este aspecto.\n",
    "\n",
    "- Uso en la industria: Python es ampliamente utilizado en la industria para aplicaciones de ciencia de datos, aprendizaje automático e inteligencia artificial. Su flexibilidad, rendimiento y capacidad de integración lo hacen popular entre los desarrolladores y científicos de datos. R es más comúnmente utilizado en entornos académicos y de investigación, así como en ciertos sectores especializados, como la biología y la econometría.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;\">\n",
    "\n",
    "En el campo de análisis de datos estadísticos, pandas, como biblioteca de Python, ha experimentado un crecimiento significativo y se ha convertido en una herramienta poderosa y ampliamente adoptada. A continuación, se presenta una comparación entre pandas, R, SQL y otras herramientas en términos de su estado actual en el análisis de datos estadísticos:\n",
    "\n",
    "#### pandas (Python):\n",
    "\n",
    "- Pandas ofrece una amplia gama de funcionalidades para el análisis de datos estadísticos.\n",
    "- Proporciona estructuras de datos flexibles como DataFrames y Series, que permiten el manejo eficiente de datos estructurados.\n",
    "- Ofrece una amplia gama de operaciones de manipulación y transformación de datos, como agrupamiento, filtrado, pivote y combinación de datos.\n",
    "- Integra fácilmente con otras bibliotecas de Python para análisis numérico y visualización de datos, como NumPy, Matplotlib y Seaborn.\n",
    "- Es ampliamente utilizado en la comunidad de análisis de datos en Python y cuenta con una gran cantidad de recursos y documentación disponibles.\n",
    "\n",
    "#### R:\n",
    "\n",
    "- R es un lenguaje y entorno de programación específicamente diseñado para el análisis estadístico y gráfico.\n",
    "- Ofrece una amplia gama de paquetes y bibliotecas estadísticas para diversas técnicas de modelado y análisis de datos.\n",
    "- Tiene una sintaxis especializada y orientada a análisis estadístico, lo que lo hace adecuado para usuarios con experiencia en estadística.\n",
    "- Es especialmente conocido por su capacidad en estadística descriptiva, modelado lineal y análisis gráfico.\n",
    "- Tiene una comunidad activa y cuenta con una amplia gama de recursos y documentación.\n",
    "\n",
    "#### SQL:\n",
    "\n",
    "- SQL (Structured Query Language) es un lenguaje de consulta utilizado principalmente para administrar y consultar bases de datos relacionales.\n",
    "- Permite realizar consultas y manipulaciones de datos en bases de datos, incluido el análisis estadístico básico.\n",
    "- Proporciona funciones agregadas y operaciones para calcular estadísticas descriptivas, realizar agrupaciones y filtrar datos.\n",
    "- Es especialmente útil cuando se trabaja con grandes conjuntos de datos almacenados en bases de datos relacionales.\n",
    "- Al combinar SQL con otras herramientas de análisis, como pandas o R, se puede lograr un análisis más completo.\n",
    "\n",
    "#### Otras herramientas:\n",
    "\n",
    "- Hay otras herramientas y bibliotecas disponibles para el análisis estadístico, como MATLAB, SAS y SPSS.\n",
    "- Estas herramientas tienen características especializadas en análisis estadístico y modelado, y son ampliamente utilizadas en entornos académicos -y corporativos.\n",
    "- Cada una de estas herramientas tiene su propia sintaxis y enfoque para el análisis estadístico, y su elección depende de las necesidades y preferencias específicas del usuario.\n",
    "\n",
    "En conclusión, aunque pandas ha ganado popularidad en el análisis de datos estadísticos debido a su integración con el ecosistema de Python, su amplia gama de funcionalidades y su facilidad de uso. R sigue siendo una opción sólida para usuarios con experiencia en estadística y análisis de datos. SQL se utiliza principalmente para el análisis de datos almacenados en bases de datos relacionales. En última instancia, la elección entre estas herramientas depende de los requisitos y conocimientos específicos\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "[1] NumPy. (2022). numpy.memmap. Recuperado el 23 de mayo de 2023, de https://numpy.org/doc/stable/reference/generated/numpy.memmap.html\n",
    "\n",
    "[2] Jackeray, S. (2020). A comparative review between programming tools used in data science."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
